{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#휴대폰 포멧(오전오후)\n",
        "import re\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# 파일 업로드\n",
        "uploaded = files.upload()\n",
        "file_content = list(uploaded.values())[0]\n",
        "decoded = io.StringIO(file_content.decode('utf-8'))\n",
        "\n",
        "messages = []\n",
        "last_msg = None\n",
        "\n",
        "# 정규식\n",
        "msg_line_pattern = re.compile(r\"^(\\d{4}\\. \\d{1,2}\\. \\d{1,2}\\. (오전|오후) \\d{1,2}:\\d{2}), (.*) : (.*)$\")\n",
        "system_msg_pattern = re.compile(r\"^\\d{4}\\. \\d{1,2}\\. \\d{1,2}\\. (오전|오후) \\d{1,2}:\\d{2}: .*$\")\n",
        "date_line_pattern = re.compile(r\"^\\d{4}년 \\d{1,2}월 \\d{1,2}일 \\S요일$\")\n",
        "\n",
        "# 한 줄씩 읽기\n",
        "for line in decoded:\n",
        "    line = line.strip()\n",
        "\n",
        "    # 무시할 조건\n",
        "    if not line or system_msg_pattern.match(line) or date_line_pattern.match(line):\n",
        "        continue\n",
        "\n",
        "    # 메시지 매칭\n",
        "    msg_match = msg_line_pattern.match(line)\n",
        "    if msg_match:\n",
        "        _, _, user, text = msg_match.groups()\n",
        "\n",
        "        # \"이모티콘\", \"사진\", \"동영상\" 이 포함되면 skip\n",
        "        if text in [\"이모티콘\", \"사진\", \"동영상\"]:\n",
        "            continue\n",
        "\n",
        "        last_msg = {'User': user.strip(), 'Message': text.strip()}\n",
        "        messages.append(last_msg)\n",
        "    else:\n",
        "        # 줄바꿈 메시지 이어붙이기\n",
        "        if last_msg:\n",
        "            last_msg['Message'] += \"\\n\" + line.strip()\n",
        "\n",
        "# DataFrame 변환\n",
        "df = pd.DataFrame(messages)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "QjaG-pQSOIWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#핸드폰 포멧(24시)\n",
        "import re\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "def katalk_msg_parse_simple(uploaded_file):\n",
        "    messages = []\n",
        "    last_msg = None\n",
        "\n",
        "    # 정규식 패턴 정의\n",
        "    msg_line_pattern = re.compile(r\"^(\\d{4}\\. \\d{1,2}\\. \\d{1,2}\\. \\d{1,2}:\\d{2}), (.*) : (.*)$\")\n",
        "    system_msg_pattern = re.compile(r\"^\\d{4}\\. \\d{1,2}\\. \\d{1,2}\\. \\d{1,2}:\\d{2}: .*$\")\n",
        "    date_line_pattern = re.compile(r\"^\\d{4}년 \\d{1,2}월 \\d{1,2}일 \\S요일$\")\n",
        "\n",
        "    file_content = list(uploaded_file.values())[0]\n",
        "    decoded = io.StringIO(file_content.decode('utf-8'))\n",
        "\n",
        "    for line in decoded:\n",
        "        line = line.strip()\n",
        "\n",
        "        if not line or system_msg_pattern.match(line) or date_line_pattern.match(line):\n",
        "            continue\n",
        "\n",
        "        msg_match = msg_line_pattern.match(line)\n",
        "        if msg_match:\n",
        "            _, user, text = msg_match.groups()\n",
        "            last_msg = {'User': user.strip(), 'Message': text.strip()}\n",
        "            messages.append(last_msg)\n",
        "        else:\n",
        "            if last_msg:\n",
        "                last_msg['Message'] += \"\\n\" + line.strip()\n",
        "\n",
        "    df = pd.DataFrame(messages)\n",
        "    return df\n",
        "\n",
        "df = katalk_msg_parse_simple(uploaded)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "elyp26lrD6YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#컴퓨터 포멧\n",
        "import re\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "def parse_kakao_pc_chat():\n",
        "    uploaded = files.upload()  # 파일 업로드\n",
        "    file_name = list(uploaded.keys())[0]\n",
        "    content = uploaded[file_name].decode('utf-8')\n",
        "    lines = content.strip().split('\\n')\n",
        "\n",
        "    data = []\n",
        "    last_user = None\n",
        "    last_msg = \"\"\n",
        "\n",
        "    msg_pattern = re.compile(r\"^\\[(.+?)\\] \\[(.+?)\\] (.+)$\")\n",
        "    skip_patterns = [\n",
        "        re.compile(r\"^-{5,}\"),              # 날짜 구분선\n",
        "        re.compile(r\"^\\*\\(안내\\)\"),         # 시스템 메시지\n",
        "    ]\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line or any(p.match(line) for p in skip_patterns):\n",
        "            continue\n",
        "        if \"님과 카카오톡 대화\" in line or \"저장한 날짜\" in line:\n",
        "            continue\n",
        "\n",
        "        match = msg_pattern.match(line)\n",
        "        if match:\n",
        "            if last_user is not None:\n",
        "                data.append({'User': last_user, 'Message': last_msg.strip()})\n",
        "            last_user = match.group(1)\n",
        "            last_msg = match.group(3)\n",
        "        else:\n",
        "            if last_user:\n",
        "                last_msg += \"\\n\" + line\n",
        "\n",
        "    if last_user:\n",
        "        data.append({'User': last_user, 'Message': last_msg.strip()})\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# 실행\n",
        "df = parse_kakao_pc_chat()\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "pceZVRsP0uIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(df)"
      ],
      "metadata": {
        "id": "_g6sJ0L00uGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#줄바꿈 합치는곳\n",
        "merged_df = pd.DataFrame(columns=['User', 'Message'])\n",
        "current_user = None\n",
        "current_message = \"\"\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    if current_user is None:\n",
        "        current_user = row['User']\n",
        "        current_message = row['Message']\n",
        "    elif row['User'] == current_user:\n",
        "        current_message += \" \" + row['Message']  # ← 여기서 줄바꿈 대신 공백\n",
        "    else:\n",
        "        merged_df = pd.concat(\n",
        "            [merged_df, pd.DataFrame([{'User': current_user, 'Message': current_message.strip()}])],\n",
        "            ignore_index=True\n",
        "        )\n",
        "        current_user = row['User']\n",
        "        current_message = row['Message']\n",
        "\n",
        "# 마지막 메시지도 추가\n",
        "if current_user:\n",
        "    merged_df = pd.concat(\n",
        "        [merged_df, pd.DataFrame([{'User': current_user, 'Message': current_message.strip()}])],\n",
        "        ignore_index=True\n",
        "    )\n"
      ],
      "metadata": {
        "id": "FKjQdgq_PbYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#대화 순서 정렬\n",
        "my_name = \"이도현\"\n",
        "\n",
        "def clean_text(text):\n",
        "    if any(x in text for x in [\"이모티콘\", \"사진\", \"동영상\", \"삭제된 메시지입니다.\"]):\n",
        "        return None\n",
        "    return text.strip() if text.strip() else None\n",
        "\n",
        "pairs = []\n",
        "i = 0\n",
        "while i < len(merged_df) - 1:\n",
        "    user1, msg1 = merged_df.iloc[i]['User'], merged_df.iloc[i]['Message']\n",
        "    user2, msg2 = merged_df.iloc[i + 1]['User'], merged_df.iloc[i + 1]['Message']\n",
        "\n",
        "    if user1 == my_name and user2 != my_name:\n",
        "        cleaned_prompt = clean_text(msg1)\n",
        "        cleaned_response = clean_text(msg2)\n",
        "        if cleaned_prompt and cleaned_response:\n",
        "            pairs.append({\n",
        "                'user': user1,\n",
        "                'partner': user2,\n",
        "                'prompt': cleaned_prompt,\n",
        "                'response': cleaned_response\n",
        "            })\n",
        "        i += 2\n",
        "    else:\n",
        "        i += 1\n",
        "\n",
        "dataa = pd.DataFrame(pairs)\n"
      ],
      "metadata": {
        "id": "uJKNSwVg0uD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(dataa)"
      ],
      "metadata": {
        "id": "c7D7r4bI0uCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "\n",
        "checkpoint = \"skt/kogpt2-base-v2\"\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
        "    checkpoint,\n",
        "    bos_token='<s>', eos_token='</s>', unk_token='<unk>',\n",
        "    pad_token='<pad>', mask_token='<mask>'\n",
        ")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n"
      ],
      "metadata": {
        "id": "ca8sxPMo1DQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset.from_pandas(dataa).map(\n",
        "    lambda x: {\"text\": f\"{x['prompt']}\\n{x['response']}</s>\"}\n",
        ")\n"
      ],
      "metadata": {
        "id": "iGod3RgI1GFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_set_labels(example):\n",
        "    tokenized = tokenizer(\n",
        "        example[\"text\"],\n",
        "        truncation=True,\n",
        "        max_length=1024,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
        "    return tokenized\n",
        "\n",
        "dataset = dataset.map(tokenize_and_set_labels, batched=True).train_test_split(test_size=0.1)\n"
      ],
      "metadata": {
        "id": "xlglp0x01IXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = GPT2LMHeadModel.from_pretrained(checkpoint).to(device)\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n"
      ],
      "metadata": {
        "id": "i4oEomz51NVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"kogpt2-finetuned-chat\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=3,\n",
        "    save_total_limit=1,\n",
        "    logging_steps=20,\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=True if torch.cuda.is_available() else False,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset['train'],\n",
        "    eval_dataset=dataset['test'],\n",
        "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "z5bS17Jb1O1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"### Me: 오늘 머함? \\n### You:\"\n",
        "input_ids = tokenizer.encode(prompt, return_tensors='pt').to(model.device)\n",
        "\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    max_new_tokens=30,           # 딱 한두 문장 분량\n",
        "    do_sample=True,\n",
        "    top_k=30,                    # 낮게: 흔한 말 위주로 선택\n",
        "    top_p=0.6,                   # 확률 누적 제한\n",
        "    temperature=0.5,             # 덜 산만하게\n",
        "    repetition_penalty=1.2,      # 반복 감점\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        "    eos_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "id": "sCw2SeCt_CS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0)\n",
        "\n",
        "output = generator(\n",
        "    \"### Me: 여기다가 입력하면 됩니다 \\n### You:\",\n",
        "    max_length=100,\n",
        "    do_sample=True,\n",
        "    temperature=0.8,     # 다양성 높이되 너무 높지 않게\n",
        "    top_k=50,            # 높은 확률 토큰만 선택\n",
        "    top_p=0.9,           # 누적 확률 90% 이내에서 샘플링\n",
        "    repetition_penalty=1.2,  # 반복 방지 핵심!\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "print(output[0]['generated_text'])\n"
      ],
      "metadata": {
        "id": "6IuRPe90EM3Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}